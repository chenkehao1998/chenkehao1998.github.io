(window.webpackJsonp=window.webpackJsonp||[]).push([[98],{621:function(e,s,r){e.exports=r.p+"assets/img/da36d9f8c4c9d01d3d2c0a5659e54731.58a03a14.png"},930:function(e,s,r){"use strict";r.r(s);var t=r(3),f=Object(t.a)({},(function(){var e=this,s=e._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("p",[s("img",{attrs:{src:r(621),alt:"da36d9f8c4c9d01d3d2c0a5659e54731.png"}})]),e._v(" "),s("h1",{attrs:{id:"_1-过程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-过程"}},[e._v("#")]),e._v(" 1. 过程")]),e._v(" "),s("ol",[s("li",[s("p",[e._v("发送请求：客户端随便择一个node发送请求过去，这个被发送请求的Node是协调节点")])]),e._v(" "),s("li",[s("p",[e._v("路由：协调节点对document进行（hash）选择shard，将请求转发给对应的node（有primary shard）")])]),e._v(" "),s("li",[s("p",[e._v("处理与同步：实际的node上的primary shard处理请求，然后将数据同步到replica node")])]),e._v(" "),s("li",[s("p",[e._v("返回成功信息：coordinating node，如果发现primary node和所有replica node都搞定之后，就返回响应结果给客户端")])])]),e._v(" "),s("h1",{attrs:{id:"底层原理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#底层原理"}},[e._v("#")]),e._v(" 底层原理")]),e._v(" "),s("p",[e._v("1）先写入buffer，在buffer里的时候数据是搜索不到的；同时将数据写入translog日志文件")]),e._v(" "),s("p",[e._v("2）如果buffer快满了，或者到一定时间，就会将buffer数据refresh到一个新的segment file中，但是此时数据不是直接进入segment file的磁盘文件的，而是先进入os cache的。这个过程就是refresh。")]),e._v(" "),s("p",[e._v("每隔1秒钟，es将buffer中的数据写入一个新的segment file，每秒钟会产生一个新的磁盘文件，segment file，这个segment file中就存储最近1秒内buffer中写入的数据")]),e._v(" "),s("p",[e._v("但是如果buffer里面此时没有数据，那当然不会执行refresh操作咯，每秒创建换一个空的segment file，如果buffer里面有数据，默认1秒钟执行一次refresh操作，刷入一个新的segment file中")]),e._v(" "),s("p",[e._v("操作系统里面，磁盘文件其实都有一个东西，叫做os cache，操作系统缓存，就是说数据写入磁盘文件之前，会先进入os cache，先进入操作系统级别的一个内存缓存中去")]),e._v(" "),s("p",[e._v("只要buffer中的数据被refresh操作，刷入os cache中，就代表这个数据就可以被搜索到了")]),e._v(" "),s("p",[e._v("为什么叫es是准实时的？NRT，near real-time，准实时。默认是每隔1秒refresh一次的，所以es是准实时的，因为写入的数据1秒之后才能被看到。")]),e._v(" "),s("p",[e._v("可以通过es的restful api或者java api，手动执行一次refresh操作，就是手动将buffer中的数据刷入os cache中，让数据立马就可以被搜索到。")]),e._v(" "),s("p",[e._v("只要数据被输入os cache中，buffer就会被清空了，因为不需要保留buffer了，数据在translog里面已经持久化到磁盘去一份")]),e._v(" "),s("p",[e._v("3）只要数据进入os cache，此时就可以让这个segment file的数据对外提供搜索了")]),e._v(" "),s("p",[e._v("4）重复1~3步骤，新的数据不断进入buffer和translog，不断将buffer数据写入一个又一个新的segment file中去，每次refresh完buffer清空，translog保留。随着这个过程推进，translog会变得越来越大。当translog达到一定长度的时候，就会触发commit操作。")]),e._v(" "),s("p",[e._v("buffer中的数据，倒是好，每隔1秒就被刷到os cache中去，然后这个buffer就被清空了。所以说这个buffer的数据始终是可以保持住不会填满es进程的内存的。")]),e._v(" "),s("p",[e._v("每次一条数据写入buffer，同时会写入一条日志到translog日志文件中去，所以这个translog日志文件是不断变大的，当translog日志文件大到一定程度的时候，就会执行commit操作。")]),e._v(" "),s("p",[e._v("5）commit操作发生第一步，就是将buffer中现有数据refresh到os cache中去，清空buffer")]),e._v(" "),s("p",[e._v("6）将一个commit point写入磁盘文件，里面标识着这个commit point对应的所有segment file")]),e._v(" "),s("p",[e._v("7）强行将os cache中目前所有的数据都fsync到磁盘文件中去")]),e._v(" "),s("p",[e._v("translog日志文件的作用是什么？就是在你执行commit操作之前，数据要么是停留在buffer中，要么是停留在os cache中，无论是buffer还是os cache都是内存，一旦这台机器死了，内存中的数据就全丢了。")]),e._v(" "),s("p",[e._v("所以需要将数据对应的操作写入一个专门的日志文件，translog日志文件中，一旦此时机器宕机，再次重启的时候，es会自动读取translog日志文件中的数据，恢复到内存buffer和os cache中去。")]),e._v(" "),s("p",[e._v("commit操作：1、写commit point；2、将os cache数据fsync强刷到磁盘上去；3、清空translog日志文件")]),e._v(" "),s("p",[e._v("8）将现有的translog清空，然后再次重启启用一个translog，此时commit操作完成。默认每隔30分钟会自动执行一次commit，但是如果translog过大，也会触发commit。整个commit的过程，叫做flush操作。我们可以手动执行flush操作就是将所有os cache数据刷到磁盘文件中去。")]),e._v(" "),s("p",[e._v("不叫做commit操作，flush操作。es中的flush操作，就对应着commit的全过程。我们也可以通过es api，手动执行flush操作，手动将os cache中的数据fsync强刷到磁盘上去，记录一个commit point，清空translog日志文件。")]),e._v(" "),s("p",[e._v("9）translog其实也是先写入os cache的，默认每隔5秒刷一次到磁盘中去，所以默认情况下，可能有5秒的数据会仅仅停留在buffer或者translog文件的os cache中，如果此时机器挂了，会丢失5秒钟的数据。但是这样性能比较好，最多丢5秒的数据。也可以将translog设置成每次写操作必须是直接fsync到磁盘，但是性能会差很多。")]),e._v(" "),s("p",[e._v("实际上你在这里，如果面试官没有问你es丢数据的问题，你可以在这里给面试官炫一把，你说，其实es第一是准实时的，数据写入1秒后可以搜索到；可能会丢失数据的，你的数据有5秒的数据，停留在buffer、translog os cache、segment file os cache中，有5秒的数据不在磁盘上，此时如果宕机，会导致5秒的数据丢失。")]),e._v(" "),s("p",[e._v("如果你希望一定不能丢失数据的话，你可以设置个参数，官方文档，百度一下。每次写入一条数据，都是写入buffer，同时写入磁盘上的translog，但是这会导致写性能、写入吞吐量会下降一个数量级。本来一秒钟可以写2000条，现在你一秒钟只能写200条，都有可能。")]),e._v(" "),s("p",[e._v("10）如果是删除操作，commit的时候会生成一个.del文件，里面将某个doc标识为deleted状态，那么搜索的时候根据.del文件就知道这个doc被删除了")]),e._v(" "),s("p",[e._v("11）如果是更新操作，就是将原来的doc标识为deleted状态，然后新写入一条数据")]),e._v(" "),s("p",[e._v("12）buffer每次refresh一次，就会产生一个segment file，所以默认情况下是1秒钟一个segment file，segment file会越来越多，此时会定期执行merge")]),e._v(" "),s("p",[e._v("13）每次merge的时候，会将多个segment file合并成一个，同时这里会将标识为deleted的doc给物理删除掉，然后将新的segment file写入磁盘，这里会写一个commit point，标识所有新的segment file，然后打开segment file供搜索使用，同时删除旧的segment file。")]),e._v(" "),s("p",[e._v("es里的写流程，有4个底层的核心概念，refresh、flush、translog、merge")]),e._v(" "),s("p",[e._v("当segment file多到一定程度的时候，es就会自动触发merge操作，将多个segment file给merge成一个segment file。")])])}),[],!1,null,null,null);s.default=f.exports}}]);