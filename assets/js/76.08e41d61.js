(window.webpackJsonp=window.webpackJsonp||[]).push([[76],{664:function(_,i,t){_.exports=t.p+"assets/img/01__E5_88_86_E5_BA_93_E5_88_86_E_1e8e0e7d789e45ea8.188949b4.png"},665:function(_,i,t){_.exports=t.p+"assets/img/02_snowflake_E7_AE_97_E6_B3_95_35436340cc1241149bd.83c27bdd.png"},969:function(_,i,t){"use strict";t.r(i);var v=t(3),d=Object(v.a)({},(function(){var _=this,i=_._self._c;return i("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[i("h1",{attrs:{id:"数据库自增id"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#数据库自增id"}},[_._v("#")]),_._v(" 数据库自增ID")]),_._v(" "),i("p",[_._v("这个就是说你的系统里每次得到一个id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个id。拿到这个id之后再往对应的分库分表里去写入。")]),_._v(" "),i("p",[_._v("这个方案的好处就是方便简单，谁都会用；缺点就是单库生成自增id，要是高并发的话，就会有瓶颈的；如果你硬是要改进一下，那么就专门开一个服务出来，这个服务每次就拿到当前id最大值，然后自己递增几个id，一次性返回一批id，然后再把当前最大id值修改成递增几个id之后的一个值；但是无论怎么说都是基于单个数据库。")]),_._v(" "),i("p",[_._v("适合的场景：你分库分表就俩原因，要不就是单库并发太高，要不就是单库数据量太大；除非是你并发不高，但是数据量太大导致的分库分表扩容，你可以用这个方案，因为可能每秒最高并发最多就几百，那么就走单独的一个库和表生成自增主键即可。")]),_._v(" "),i("p",[_._v("并发很低，几百/s，但是数据量大，几十亿的数据，所以需要靠分库分表来存放海量的数据\n"),i("img",{attrs:{src:t(664),alt:"01_分库分表的id主键问题"}})]),_._v(" "),i("h1",{attrs:{id:"uuid"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#uuid"}},[_._v("#")]),_._v(" UUID")]),_._v(" "),i("p",[_._v("好处就是本地生成，不要基于数据库来了；不好之处就是，uuid太长了，作为主键性能太差了，不适合用于主键。")]),_._v(" "),i("p",[_._v("适合的场景：如果你是要随机生成个什么文件名了，编号之类的，你可以用uuid，但是作为主键是不能用uuid的。")]),_._v(" "),i("h1",{attrs:{id:"获取系统时间戳"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#获取系统时间戳"}},[_._v("#")]),_._v(" 获取系统时间戳")]),_._v(" "),i("p",[_._v("这个就是获取当前时间即可，但是问题是，并发很高的时候，比如一秒并发几千，会有重复的情况，这个是肯定不合适的。基本就不用考虑了。")]),_._v(" "),i("p",[_._v("适合的场景：一般如果用这个方案，是将当前时间跟很多其他的业务字段拼接起来，作为一个id，如果业务上你觉得可以接受，那么也是可以的。你可以将别的业务字段值跟当前时间拼接起来，组成一个全局唯一的编号，订单编号，时间戳 + 用户id + 业务含义编码")]),_._v(" "),i("h1",{attrs:{id:"snowflake算法-雪花算法"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#snowflake算法-雪花算法"}},[_._v("#")]),_._v(" Snowflake算法（雪花算法）")]),_._v(" "),i("p",[_._v("twitter开源的分布式id生成算法，就是把一个64位的long型的id，1个bit是不用的，用其中的41 bit作为毫秒数，用10 bit作为工作机器id，12 bit作为序列号")]),_._v(" "),i("p",[_._v("1 bit：不用，为啥呢？因为二进制里第一个bit为如果是1，那么都是负数，但是我们生成的id都是正数，所以第一个bit统一都是0")]),_._v(" "),i("p",[_._v("41 bit：表示的是时间戳，单位是毫秒。41 bit可以表示的数字多达2^41 - 1，也就是可以标识2 ^ 41 - 1个毫秒值，换算成年就是表示69年的时间。")]),_._v(" "),i("p",[_._v("10 bit：记录工作机器id，代表的是这个服务最多可以部署在2^10台机器上哪，也就是1024台机器。但是10 bit里5个bit代表机房id，5个bit代表机器id。意思就是最多代表2 ^ 5个机房（32个机房），每个机房里可以代表2 ^ 5个机器（32台机器）。")]),_._v(" "),i("p",[_._v("12 bit：这个是用来记录同一个毫秒内产生的不同id，12 bit可以代表的最大正整数是2 ^ 12 - 1 = 4096，也就是说可以用这个12bit代表的数字来区分同一个毫秒内的4096个不同的id")]),_._v(" "),i("p",[_._v("64位的long型的id，64位的long -> 二进制")]),_._v(" "),i("p",[i("code",[_._v("0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000")])]),_._v(" "),i("p",[_._v("2018-01-01 10:00:00 -> 做了一些计算，再换算成一个二进制，41bit来放 -> 0001100 10100010 10111110 10001001")]),_._v(" "),i("p",[_._v("机房id，17 -> 换算成一个二进制 -> 10001")]),_._v(" "),i("p",[_._v("机器id，25 -> 换算成一个二进制 -> 11001")]),_._v(" "),i("p",[_._v("snowflake算法服务，会判断一下，当前这个请求是否是，机房17的机器25，在2175/11/7 12:12:14时间点发送过来的第一个请求，如果是第一个请求")]),_._v(" "),i("p",[_._v("假设，在2175/11/7 12:12:14时间里，机房17的机器25，发送了第二条消息，snowflake算法服务，会发现说机房17的机器25，在2175/11/7 12:12:14时间里，在这一毫秒，之前已经生成过一个id了，此时如果你同一个机房，同一个机器，在同一个毫秒内，再次要求生成一个id，此时我只能把加1")]),_._v(" "),i("p",[_._v("比如我们来观察上面的那个，就是一个典型的二进制的64位的id，换算成10进制就是910499571847892992。")]),_._v(" "),i("p",[i("img",{attrs:{src:t(665),alt:"02_snowflake算法"}})]),_._v(" "),i("p",[_._v("所以你自己利用这个工具类，自己搞一个服务，然后对每个机房的每个机器都初始化这么一个东西，刚开始这个机房的这个机器的序号就是0。然后每次接收到一个请求，说这个机房的这个机器要生成一个id，你就找到对应的Worker，生成。")]),_._v(" "),i("p",[_._v("他这个算法生成的时候，会把当前毫秒放到41 bit中，然后5 bit是机房id，5 bit是机器id，接着就是判断上一次生成id的时间如果跟这次不一样，序号就自动从0开始；要是上次的时间跟现在还是在一个毫秒内，他就把seq累加1，就是自动生成一个毫秒的不同的序号。")]),_._v(" "),i("p",[_._v("这个算法那，可以确保说每个机房每个机器每一毫秒，最多生成4096个不重复的id。")]),_._v(" "),i("p",[_._v("利用这个snowflake算法，你可以开发自己公司的服务，甚至对于机房id和机器id，反正给你预留了5 bit + 5 bit，你换成别的有业务含义的东西也可以的。")]),_._v(" "),i("p",[_._v("这个snowflake算法相对来说还是比较靠谱的，所以你要真是搞分布式id生成，如果是高并发啥的，那么用这个应该性能比较好，一般每秒几万并发的场景，也足够你用了。")])])}),[],!1,null,null,null);i.default=d.exports}}]);